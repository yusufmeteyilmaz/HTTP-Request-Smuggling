To understand http better, let's make a basic example:
- Send a http request, receive a response

https://www.internalpointers.com/post/making-http-requests-sockets-python
Socket, creates a way to communicate between 2 devices.

```
import socket
sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
sock.connect(("httpbin.org", 80))
sock.send(b"POST /post HTTP/1.0\r\nHost: httpbin.org\r\nContent-Length:5\r\n\r\n12345")

response = sock.recv(2048)
print(response.decode())

sock.close()
```

But it didn't go well, I couldn't get all of the response, it wasn't stable.
![](../Images/2.5-%20Little%20bit%20coding/not_stable.png)

The reason:
https://stackoverflow.com/questions/17667903/python-socket-receive-large-amount-of-data

"TCP/IP is a _stream-based_ protocol, not a _message-based_ protocol."

So, there’s a chance we might not receive all the data at once because it arrives in TCP segments. Imagine you ordered a Raspberry Pi, an SD card, and a power supply. You can't use the Raspberry Pi without these components (well, technically, you could use USB storage as well). You have to wait until all of them arrive, which could be one day apart or at the same time. But the key point is, you can't use it until everything arrives.

https://www.wireshark.org/docs/wsdg_html_chunked/ChDissectReassemble.html#TcpDissectPdus
"When dissecting an application layer protocol you cannot assume that each TCP packet contains exactly one application layer message. One application layer message can be split into several TCP packets."

Actually we can see this behaviour by eye:
https://stackoverflow.com/questions/71368858/what-does-http-traffic-that-doesnt-show-get-post-put-etc-signify-wireshark#:~:text=The%20HTTP%20response%20is%20split,in%20the%20first%20TCP%20segment.

Sometimes it behave like this, response comes in one part:

![](../Images/2.5-%20Little%20bit%20coding/full_response.png)

Sometimes in multiple parts:
![](../Images/2.5-%20Little%20bit%20coding/part1_response.png)

![](../Images/2.5-%20Little%20bit%20coding/part2_response.png)

We need to fix this first. Let's read data part by part.
We can loop over again until we get full response:

```
response = b""
while True:
    chunk = sock.recv(4096)
    if len(chunk) == 0:
        break
    response += chunk
```

If connection ends, socket.recv() would return 0, so our loop can end.

Note: https://gist.github.com/limingzju/6483619
I played with it a few times, I created a echo.py file as server.
I used my rpi as server, I connected from windows. (ncat)
When I press Ctrl+C, it sent [RST, ACK], resulting "ConnectionResetError: [Errno 104] Connection reset by peer" error on server side.
When I press Ctrl+Z + Enter, it sent [FIN, ACK] packet,
connection ended as expected. (No errors)


![](../Images/2.5-%20Little%20bit%20coding/cool_http1.0.png)

Works like a charm! But we used HTTP/1.0.

What would happened if we want to use HTTP/1.1:
If we just change `HTTP/1.0` to `HTTP/1.1` and run the script, it will stuck for a long time, why is that?

Because in HTTP/1.0 we open a tcp connection, send a request and tcp connection ends.
socket.recv() detects this and our loop stops & prints response.

But in HTTP/1.1 we use same tcp connection all the time, server doesn't close tcp connection immediately, so it stuck. The reason we get response after awhile is, server does end tcp connection after seeing not interaction by us. But it can take longer, as it varies from server to server, and it's not always reliable

So we need a clever way to confirm we get all the data required and close the connection. Of course we can wait like 10 seconds while iterating over sock.recv().
But that method wouldn't be reliable right?
Let's think...
We sent a request, receive a data.
We need to make sure we get all the data before closing the connection.

But how can we know much data is there supposed to be?

Here it comeeeees! "Content-Length" header in the response!!!
It will tell us how much data we need to read, that is it actually.

Let's try something basic.
```
HTTP/1.1 200 OK\r\n
Date: Sun, 10 Nov 2024 12:21:47 GMT\r\n
Content-Type: application/json\r\n
Content-Length: 296\r\n
Connection: keep-alive\r\n
Server: gunicorn/19.9.0\r\n
Access-Control-Allow-Origin: *\r\n
Access-Control-Allow-Credentials: true\r\n\r\n
```

We will read data up to \r\n\r\n, rest of the received data is response body.
We will decide how much to read by looking Content-Length header.

![](../Images/2.5-%20Little%20bit%20coding/better_http1.1.png)

Cool! So far:
We sent a HTTP/1.0 request and received a response.
We sent a HTTP/1.1 request and received a response.

What about 2 requests in one go?

![](../Images/2.5-%20Little%20bit%20coding/multi_http1.1.png)

Notice, I used same connection, to understand http request smuggling better.

Here is how it looked like in wireshark:

![](../Images/2.5-%20Little%20bit%20coding/wireshark_1_tcp_connection.png)

#### What happens we send wrong content-length header?
![](../Images/2.5-%20Little%20bit%20coding/wrong_content_length.png)

First request's Content-Length is 4 but it has 5 bytes of data "CoolP"
What would happen?
![](../Images/2.5-%20Little%20bit%20coding/wrong_content_length_0.png)

Method not allowed?!?
Why ?

Here is the fun part begins!

```
POST /post HTTP/1.1\r\nHost: httpbin.org\r\nContent-Length: 4\r\n\r\nCoolP
```

```
POST /post HTTP/1.1\r\nHost: httpbin.org\r\nContent-Length: 5\r\n\r\nstuff
```

We sent 2 requests in same tcp connection.
We sent our request, waited for the response, and then sent a second request.

\-------------------------------
Main idea is how server process our request.

To understand how server process http request, remember how did we process a http response?

- We read until \r\n\r\n, split response in 2 parts: header and body
- Read the value of Content-Length header
- Read according to CL header's value. (e.g, CL=5, read 5 bytes)

What if there was a more than 1 response?

- We read until \r\n\r\n, split response in 2 parts: header and body
- Read the value of Content-Length header
- Read body according to CL header's value. (e.g, CL=5, read 5 bytes)
- We read until \r\n\r\n, split response in 2 parts: header and body
- Read the value of Content-Length header
- Read body according to CL header's value. (e.g, CL=7, read 7 bytes)

Another example:
```
HTTP/1.1 200 OK
Content-Length: 2

hi
```

```
HTTP/1.1 200 OK
Content-Length: 5

hello
```

It is better to imagine everything in a line, because it is byte stream.

```
HTTP/1.1 200 OK\r\nContent-Length: 2\r\n\r\nhiHTTP/1.1 200 OK\r\nContent-Length: 5\r\n\r\nhello
```
For the last time let's process this.
- Read until \r\n\r\n, parse headers and body
- Read 2 bytes (because CL header says so)
- read h
- read i
- End processing first response
- Read until \r\n\r\n, parse headers and body
- Read 5 bytes
- read h
- read e
- read l
- read l
- read o
- End processing second response
!!! We start reading second response as soon as first one processed !!!

\-------------------------------

Let's think what server do when it receives our request.

Server doesn't know how much data we will send!!!
It has to check Content-Length header.

```
POST /post HTTP/1.1\r\nHost: httpbin.org\r\nContent-Length: 4\r\n\r\nCoolP
```

```
POST /post HTTP/1.1\r\nHost: httpbin.org\r\nContent-Length: 5\r\n\r\nstuff
```

- Read until \r\n\r\n, parse headers and body
- Read 4 bytes (because CL header says so)
- Read C
- Read o
- Read o
- Read l
- End processing first response
- Read until \r\n\r\n, parse headers and body
- Error PPOST not a valid header.
- Return error

Why??
Because there was a leftover from first response "P", server read as Content-Length said.

```
POST /post HTTP/1.1\r\nHost: httpbin.org\r\nContent-Length: 4\r\n\r\nCoolP
```
Server read up to "P" and start waiting, why?
Because it thought P is start of a new request.
Just remaining part didn't arrive yet.

Let's use some colours.

![](../Images/2.5-%20Little%20bit%20coding/hmm_you_must_be_0.png)
![](../Images/2.5-%20Little%20bit%20coding/hmm_you_must_be_1.png)

Let's imagine 2 requests arrive at the same time, use colours again:

![](../Images/2.5-%20Little%20bit%20coding/hmm_you_must_be_2.png)

OK enough with theoretical things.

Let me first show you how to do that with Burp.
Then python then maybe with printf & netcat.

![](../Images/2.5-%20Little%20bit%20coding/first_req.png)
![](../Images/2.5-%20Little%20bit%20coding/second_req.png)

If you send second request you will get an error:
![](../Images/2.5-%20Little%20bit%20coding/second_req_err.png)
Burp sends each request in separate connections, unless specified otherwise.

Create a group:

![](../Images/2.5-%20Little%20bit%20coding/create_group.png)

Uncheck content-length header:

![](../Images/2.5-%20Little%20bit%20coding/uncheck_cl_0.png)

![](../Images/2.5-%20Little%20bit%20coding/uncheck_cl_1.png)

Send group in sequence:

![](../Images/2.5-%20Little%20bit%20coding/send_group_in_sequence.png)

![](../Images/2.5-%20Little%20bit%20coding/hi.png)

Note: If you receive an error check content-length header, sometimes burp updates it.

Wireshark:

![](../Images/2.5-%20Little%20bit%20coding/wireshark.png)

IMPORTANT!

Understand what happened above:
Our first request's body affect the second request!

But.. If you look from server's perspective:
- It got 1 request, and another request's a few bytes
- It sent 1 response, waited until second request to complete
- It got second request completely and sent a response.

Same example in python code:

![](../Images/2.5-%20Little%20bit%20coding/request_collusion_0.png)

![](../Images/2.5-%20Little%20bit%20coding/request_collusion_1.png)

Look, even though we waited before sending each request, it worked! (send req1, get resp1, send req2, get resp2)
We could have sent the requests without waiting for responses, but there’s no need to make things more complicated. (send req1, send req2, get resp1, get resp2)

I hope you understand it!

*One request can affect another request if they are on same tcp connection.*

One more!

![](../Images/2.5-%20Little%20bit%20coding/last.png)
![](../Images/2.5-%20Little%20bit%20coding/request_collusion_last.png)

![](../Images/2.5-%20Little%20bit%20coding/wireshark_1.png)

It depends how you look at that:
- Did we send 1 POST Request like that:
```
POST /post HTTP/1.1
Host: httpbin.org
Content-Length: 4 

CoolGET /404 HTTP/1.1
Host: httpbin.org
```
- or did we send 2 separate requests:
```
POST /post HTTP/1.1
Host: httpbin.org
Content-Length: 4

Cool
```

```
GET /404 HTTP/1.1
Host: httpbin.org
```

Answer is simple:
- Are you the one who send the request?
 If so, you just send a byte array, bunch of numbers, it doesn't matter how you look at it.
 - Are you server?
 Then it is 2 different requests, because you parse incoming data by looking Content-Length header. If your behaviour is different, only you know how to parse them, idk.

Ok but why we get 2 responses even though we can clearly see there is 3 requests? (how server looks)
Answer: because we designed it like that:

Python script sends a request, receives a response, sends another request, receives the response, and then closes the connection.

Closer look:

we sent a data:

```
request_data_1 = b"POST /post HTTP/1.1\r\nHost: httpbin.org\r\nContent-Length: 4\r\n\r\nCoolGET /404 HTTP/1.1\r\nHost: httpbin.org\r\n\r\n"
```
server sent 2 response:

![](../Images/2.5-%20Little%20bit%20coding/wireshark_2.png)

Our parser start by looking \r\n\r\n, parse headers&body
and read up to "whatever Content-Length header says".
So it successfully reads the first response.

Then sent second request.

![](../Images/2.5-%20Little%20bit%20coding/wireshark_3.png)

Then did the same thing. Look for \r\n\r\n, parse headers&body, check CL header, read up to whatever it says.

It started reading:

![](../Images/2.5-%20Little%20bit%20coding/wireshark_4.png)

Our parser doesn't know which request belongs to which response.

So it took previous response left in buffer.
Then closed the connection, why?
We sent 2 requests 2 responses, at least my code thought like that.
But the server saw three requests: the first two arrived at the same time, and after awhile, the third request came. However, as soon as the server was about to reply to third request, the connection was shut down.

Note: It depends too, think about how fast is our connection.
Connection may shutdown after server sends reply to third request.

If we debug the code and wait little bit before closing connection, we can get third response too!

![](../Images/2.5-%20Little%20bit%20coding/wireshark_5.png)

![](../Images/2.5-%20Little%20bit%20coding/debugging.png)

For the last time sake of demonstration:
- We sent 2 requests in once. `send_request(request_data_1)`
- Server sent back 2 response. (RespA, RespB)
- Our parser read first response. (RespA)
- We sent one more request. (ReqC) `send_request(request_data_2)`
- Our parser read second response. (RespB)
- Server sent response.  (RespC)
- We closed the connection.
We didn't ever read RespC, but in the debugger we can see it is present.
`sock.recv(4096)`

Note:
If we close connection before server send RespC,

![](../Images/2.5-%20Little%20bit%20coding/wireshark_1.png).

If we close connection after server send RespC,

![](../Images/2.5-%20Little%20bit%20coding/wireshark_5.png).

But we don't read RespC in both cases.

#### Did you get it ?

I hope you understand it!
In a single tcp connection, requests can affect each other.
In a single tcp connection, our data can affect next data.
Everything about how server sees it.
It doesn't matter how you or wireshark or someone else see it.
Everything about how server sees it.

Now you can move on to [part 3](./3-%20HTTP%20Request%20Smuggling.md)
